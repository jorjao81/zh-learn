"""LLM-based field generators for Anki cards."""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from pydantic import BaseModel


class TokenUsage(BaseModel):
    """Token usage information from an LLM API call."""
    
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    cost_usd: float = 0.0


class FieldGenerationResult(BaseModel):
    """Structured results for fields generated by an LLM."""

    structural_decomposition: Optional[str] = None
    etymology: Optional[str] = None
    token_usage: Optional[TokenUsage] = None


class FieldGenerator(ABC):
    """Interface for generating additional Anki card fields."""

    @abstractmethod
    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        """Generate fields for the given Chinese text."""
        raise NotImplementedError


class GptFieldGenerator(FieldGenerator):
    """Generate fields using an OpenAI GPT model."""

    # GPT-5 pricing per 1M tokens (August 2025 official pricing)
    PRICING = {
        "gpt-5": {"input": 1.25, "output": 10.00, "cached_input": 0.125},
        "gpt-5-mini": {"input": 0.25, "output": 2.00},
        "gpt-5-nano": {"input": 0.05, "output": 0.40},
    }

    def __init__(
        self,
        model: str,
        api_key: Optional[str] = None,
        prompt_path: Optional[str] = None,
        thinking: Optional[Dict[str, Any]] = None,
    ) -> None:
        from openai import OpenAI

        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        self.model = model
        self.thinking = thinking
        self.prompt = ""
        if prompt_path:
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.prompt = f.read()

            # Load examples from the examples directory if it exists
            from pathlib import Path

            examples_dir = Path(prompt_path).parent / "examples"
            if examples_dir.exists():
                self.prompt = self._load_prompt_with_examples(self.prompt, examples_dir)

    def _load_prompt_with_examples(self, base_prompt: str, examples_dir) -> str:
        """Load examples from the examples directory and incorporate them into the prompt."""

        examples_text = "\n\nHere are examples of the expected output format:\n\n"

        # Load structural decomposition example
        structural_example_path = examples_dir / "structural_decomposition.html"
        if structural_example_path.exists():
            with open(structural_example_path, "r", encoding="utf-8") as f:
                structural_content = f.read().strip()
            examples_text += f"**Example structural_decomposition_html for 忆:**\n```html\n{structural_content}\n```\n\n"

        # Load etymology example
        etymology_example_path = examples_dir / "etymology.html"
        if etymology_example_path.exists():
            with open(etymology_example_path, "r", encoding="utf-8") as f:
                etymology_content = f.read().strip()
            examples_text += f"**Example etymology_html for 忆:**\n```html\n{etymology_content}\n```\n\n"

        examples_text += "Please follow these formats exactly, using the same HTML structure and CSS classes.\n"

        return base_prompt + examples_text

    def _calculate_cost(self, usage_dict: dict) -> float:
        """Calculate cost in USD based on token usage."""
        if self.model not in self.PRICING:
            return 0.0
        
        pricing = self.PRICING[self.model]
        prompt_tokens = usage_dict.get("prompt_tokens", 0)
        completion_tokens = usage_dict.get("completion_tokens", 0)
        
        # Cost per 1M tokens, so divide by 1,000,000
        input_cost = (prompt_tokens * pricing["input"]) / 1_000_000
        output_cost = (completion_tokens * pricing["output"]) / 1_000_000
        
        return input_cost + output_cost

    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        import json

        messages = [
            {"role": "system", "content": self.prompt},
            {
                "role": "user",
                "content": json.dumps({"character": chinese, "pinyin": pinyin}, ensure_ascii=False),
            },
        ]
        kwargs: Dict[str, Any] = {
            "model": self.model,
            "messages": messages,
            "response_format": {"type": "json_object"},
        }
        if self.thinking:
            kwargs["thinking"] = self.thinking

        response = self.client.chat.completions.create(**kwargs)
        content = response.choices[0].message.content
        data = json.loads(content)
        
        # Extract token usage and calculate cost
        usage_dict = response.usage.dict() if response.usage else {}
        cost = self._calculate_cost(usage_dict)
        
        token_usage = TokenUsage(
            prompt_tokens=usage_dict.get("prompt_tokens", 0),
            completion_tokens=usage_dict.get("completion_tokens", 0),
            total_tokens=usage_dict.get("total_tokens", 0),
            cost_usd=cost,
        )
        
        return FieldGenerationResult(
            structural_decomposition=data.get("structural_decomposition_html"),
            etymology=data.get("etymology_html"),
            token_usage=token_usage,
        )
